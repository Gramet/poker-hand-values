{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "005cd2a9231779a260fc4bd96159dff6",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV7gYl8osN6n",
        "colab_type": "text"
      },
      "source": [
        "# Baseline for PKHND Challenge on AIcrowd\n",
        "#### Author : Ayush Shivani"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSUm05lOsN6p",
        "colab_type": "text"
      },
      "source": [
        "## To open this notebook on Google Computing platform Colab, click below!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88aqxo8isN6r",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/gist/aicrowd-bot/005cd2a9231779a260fc4bd96159dff6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1gRfdAYsN6s",
        "colab_type": "text"
      },
      "source": [
        "## Download Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFJ9S873sN6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "e782966a-4520-42c2-8a4c-ef9203fd9b77"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install numpy\n",
        "!{sys.executable} -m pip install pandas\n",
        "!{sys.executable} -m pip install scikit-learn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeakWwsFsN6z",
        "colab_type": "text"
      },
      "source": [
        "## Download data\n",
        "The first step is to download out train test data. We will be training a classifier on the train data and make predictions on test data. We submit our predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2IU3retsN60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "acfb13bb-cd78-4479-ab82-5b3e230f482b"
      },
      "source": [
        "!wget https://s3.eu-central-1.wasabisys.com/aicrowd-public-datasets/aicrowd_educational_pkhnd/data/public/test.csv\n",
        "!wget https://s3.eu-central-1.wasabisys.com/aicrowd-public-datasets/aicrowd_educational_pkhnd/data/public/train.zip\n",
        "!unzip train.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-04 12:38:00--  https://s3.eu-central-1.wasabisys.com/aicrowd-public-datasets/aicrowd_educational_pkhnd/data/public/test.csv\n",
            "Resolving s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)... 130.117.252.10, 130.117.252.16, 130.117.252.13, ...\n",
            "Connecting to s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)|130.117.252.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 538694 (526K) [text/csv]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "test.csv            100%[===================>] 526.07K   449KB/s    in 1.2s    \n",
            "\n",
            "2020-05-04 12:38:03 (449 KB/s) - ‘test.csv’ saved [538694/538694]\n",
            "\n",
            "--2020-05-04 12:38:04--  https://s3.eu-central-1.wasabisys.com/aicrowd-public-datasets/aicrowd_educational_pkhnd/data/public/train.zip\n",
            "Resolving s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)... 130.117.252.10, 130.117.252.16, 130.117.252.13, ...\n",
            "Connecting to s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)|130.117.252.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6224117 (5.9M) [application/zip]\n",
            "Saving to: ‘train.zip’\n",
            "\n",
            "train.zip           100%[===================>]   5.94M  2.87MB/s    in 2.1s    \n",
            "\n",
            "2020-05-04 12:38:07 (2.87 MB/s) - ‘train.zip’ saved [6224117/6224117]\n",
            "\n",
            "Archive:  train.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrBAEPi7sN64",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7IN8SRHsN65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF3-wX5rsN68",
        "colab_type": "text"
      },
      "source": [
        "## Load Data\n",
        "We use pandas library to load our data. Pandas loads them into dataframes which helps us analyze our data easily. Learn more about it [here](https://www.tutorialspoint.com/python_data_science/python_pandas.htm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2OCFvNysN69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_path = \"train.csv\" #path where data is stored"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-9wQgZGsN7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv(train_data_path) #load data in dataframe using pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-zLiCVfsN7E",
        "colab_type": "text"
      },
      "source": [
        "## Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlZDo7hEsN7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ad352cfa-e381-4c7e-9d8b-96ccc8e1aae9"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S1</th>\n",
              "      <th>C1</th>\n",
              "      <th>S2</th>\n",
              "      <th>C2</th>\n",
              "      <th>S3</th>\n",
              "      <th>C3</th>\n",
              "      <th>S4</th>\n",
              "      <th>C4</th>\n",
              "      <th>S5</th>\n",
              "      <th>C5</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   S1  C1  S2  C2  S3  C3  S4  C4  S5  C5  label\n",
              "0   1   1   1  13   2   4   2   3   1  12      0\n",
              "1   3  12   3   2   3  11   4   5   2   5      1\n",
              "2   1   9   4   6   1   4   3   2   3   9      1\n",
              "3   1   4   3  13   2  13   2   1   3   6      1\n",
              "4   3  10   2   7   1   2   2  11   4   9      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEwK2eGCsN7I",
        "colab_type": "text"
      },
      "source": [
        "We can see there are 11 column where first 10 column contains the cards information and the last one describing the hand it makes. 1st and 2nd column contains suit and rank of first card respectively, 3rd and 4th column suit and rank of 2nd card and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxvuStNNsN7I",
        "colab_type": "text"
      },
      "source": [
        "## Split Data into Train and Validation\n",
        "Now we want to see how well our classifier is performing, but we dont have the test data labels with us to check. What do we do ? So we split our dataset into train and validation. The idea is that we test our classifier on validation set in order to get an idea of how well our classifier works. This way we can also ensure that we dont [overfit](https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/) on the train dataset. There are many ways to do validation like [k-fold](https://machinelearningmastery.com/k-fold-cross-validation/),[leave one out](https://en.wikipedia.org/wiki/Cross-validation_(statistics), etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq0Cx2GpsN7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val= train_test_split(train_data, test_size=0.2, random_state=42) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o26BoYYsN7M",
        "colab_type": "text"
      },
      "source": [
        "Here we have selected the size of the testing data to be 20% of the total data. You can change it and see what effect it has on the accuracies. To learn more about the train_test_split function [click here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSo5PFJgsN7M",
        "colab_type": "text"
      },
      "source": [
        "Now, since we have our data splitted into train and validation sets, we need to get the label separated from the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_0ZERsusN7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,y_train = X_train.iloc[:,:-1],X_train.iloc[:,-1]\n",
        "X_val,y_val = X_val.iloc[:,:-1],X_val.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhCshmGXsN7Q",
        "colab_type": "text"
      },
      "source": [
        "## Define the Classifier\n",
        "Now we come to the juicy part. We have fixed our data and now we train a classifier. The classifier will learn the function by looking at the inputs and corresponding outputs. There are a ton of classifiers to choose from some being [Logistic Regression](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc), [SVM](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47), [Random Forests](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47), [Decision Trees](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052), etc.   \n",
        "Tip: A good model doesnt depend solely on the classifier but on the features(columns) you choose. So make sure to play with your data and keep only whats important. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpezYeGBsN7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = SVC(gamma='auto',max_iter=10)\n",
        "\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "# classifier = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R3BPgU9sN7U",
        "colab_type": "text"
      },
      "source": [
        "We have used [Support Vector Machines](https://scikit-learn.org/stable/modules/svm.html#classification) as a classifier here and set few of the parameteres. But one can set more parameters and increase the performance. To see the list of parameters visit [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baHXz79OsN7U",
        "colab_type": "text"
      },
      "source": [
        "We can also use other classifiers. To read more about sklean classifiers visit [here](https://scikit-learn.org/stable/supervised_learning.html). Try and use other classifiers to see how the performance of your model changes. Try using [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) or [MLP](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) and compare how the performance changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njy_vJ0usN7V",
        "colab_type": "text"
      },
      "source": [
        "## Train the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXU4IRKFsN7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "8bfc7290-3f40-4ba8-fda6-7c346bde5e72"
      },
      "source": [
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
              "    max_iter=10, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7n3doNcsN7a",
        "colab_type": "text"
      },
      "source": [
        "Got a warning! Dont worry, its just beacuse the number of iteration is very less(defined in the classifier in the above cell).Increase the number of iterations and see if the warning vanishes and also see how the performance changes.Do remember increasing iterations also increases the running time.( Hint: max_iter=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4gtAelJsN7a",
        "colab_type": "text"
      },
      "source": [
        "## Predict on Validation\n",
        "Now we predict our trained classifier on the validation set and evaluate our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6U379NlsN7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pucyqi0msN7e",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate the Performance\n",
        "We use the same metrics as that will be used for the test set.  \n",
        "[F1 score](https://en.wikipedia.org/wiki/F1_score) are the metrics for this challenge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kfAVYIjsN7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precision = precision_score(y_val,y_pred,average='micro')\n",
        "recall = recall_score(y_val,y_pred,average='micro')\n",
        "accuracy = accuracy_score(y_val,y_pred)\n",
        "f1 = f1_score(y_val,y_pred,average='macro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh03b3TFsN7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "99b57754-96dc-4f26-d459-2c75fb1dbeba"
      },
      "source": [
        "print(\"Accuracy of the model is :\" ,accuracy)\n",
        "print(\"Recall of the model is :\" ,recall)\n",
        "print(\"Precision of the model is :\" ,precision)\n",
        "print(\"F1 score of the model is :\" ,f1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model is : 0.49894\n",
            "Recall of the model is : 0.49894\n",
            "Precision of the model is : 0.49894\n",
            "F1 score of the model is : 0.07442511649369188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqiwy7wRsN7k",
        "colab_type": "text"
      },
      "source": [
        "# Prediction on Evaluation Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt2HKbUnsN7k",
        "colab_type": "text"
      },
      "source": [
        "## Load Test Set\n",
        "Load the test data now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEv_IDgIsN7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_test_path = \"test.csv\"\n",
        "final_test = pd.read_csv(final_test_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_OpLwqHsN7n",
        "colab_type": "text"
      },
      "source": [
        "## Predict Test Set\n",
        "Time for the moment of truth! Predict on test set and time to make the submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSxKoZQesN7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = classifier.predict(final_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxcqNSubsN7r",
        "colab_type": "text"
      },
      "source": [
        "## Save the prediction to csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz9mhcLQsN7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame(submission)\n",
        "submission.to_csv('/tmp/submission.csv',header=['label'],index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUVIb7WmsN7u",
        "colab_type": "text"
      },
      "source": [
        "Note: Do take a look at the submission format.The submission file should contain a header.For eg here it is \"label\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwk8YfzJsN7u",
        "colab_type": "text"
      },
      "source": [
        "## To download the generated csv in collab run the below command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30Kb1csMsN7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/tmp/submission.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UT1NewVsN7x",
        "colab_type": "text"
      },
      "source": [
        "### Go to [platform](https://www.aicrowd.com/challenges/aicrowd-blitz-may-2020/problems/pkhnd). Participate in the challenge and submit the submission.csv generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAT529ausN7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}